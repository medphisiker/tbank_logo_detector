# Environment Overview — `docs/2.environment.md`

> Краткое назначение: высокоуровневое описание окружений (environments) проекта — для подготовки данных, обучения моделей, инференса, разработки и продакшена. Этот документ определяет, какие окружения будут созданы и для чего они нужны. Детали зависимостей и команды установки останутся в отдельных файлах/доках (`requirements.txt`, `Dockerfile`, `env/*.yml`) на более низком уровне.

---

## Общая идея

Проект разделён на логические окружения, каждое из которых решает свою задачу и воспроизводимо:

* *data-prep* — подготовка и аннотация данных;
* *training* — обучение и валидация моделей;
* *inference* — inference / скоростной запуск модели (локально / в контейнере / на сервере);
* *service* — API (FastAPI) и orchestration между фронтом и модель-сервисом;
* *dev/test* — разработка и интеграционное тестирование (локально);
* *ci/cd* — автоматизация сборок, тестов и деплоя;
* *monitoring & experiments* — логирование, трекинг экспериментов и метрик.

Каждое окружение может быть реализовано либо как виртуальная среда (venv/conda/poetry) для локальной работы, либо как Docker-образ для воспроизводимого запуска на сервере/в облаке. Для GPU-операций (training / high-performance inference) используется Docker + NVIDIA runtime (или облачные инстансы с GPU).

---

## Перечень окружений и их назначение

### 1. `env-data-prep` — подготовка данных / аннотация

**Назначение:** собрать, аннотировать и верифицировать данные; запустить Auto-annotation pipeline (Grounding DINO → SAM → VLM verification), синтетику и скрипты для подготовки COCO.
**Использование:** локальная/серверная обработка больших наборов изображений, интеграция с OpenRouter/Qwen2.5-VL, запуск FiftyOne/CVAT инспекции.
**Реализация:**

* Локально: виртуальная среда (venv/conda) с CPU и (опционально) GPU доступом.
* В проде/на сервере: Docker-образ `tbank-data-prep:latest` с дополнительными инструментами (FiftyOne, image I/O, API clients).
  **Примечание:** возможны несколько модулей/контейнеров: `annotation-runner` (batch аннотаций), `fiftyone-ui` (визуализация).

---

### 2. `env-training` — обучение и валидация моделей

**Назначение:** обучать детекторную модель (baseline — YOLOv8, далее — эксперименты с ViT/DINOv3-бэкбоном), проводить валидацию и генерацию финальных весов.
**Использование:** запуск на GPU-инстансах (локально с T4 или в облаке), логирование экспериментов (W\&B/MLflow) и export модели (ONNX).
**Реализация:**

* Docker-образ `tbank-train:gpu` (с PyTorch, CUDA, NCCL, ultralytics и пр.).
* Возможна конфигурация для разных типов задач: `train-fast` (small модель), `train-accurate` (larger input size / augmentation).
  **Рекомендация по ресурсам:** минимум одна GPU T4 (16GB) для адекватного обучения; для ускорения — multi-GPU / cloud.

---

### 3. `env-inference` — inference / модель-сервис (model server)

**Назначение:** высокопроизводительный inference (низкая латентность, FP16), экспорт модели в ONNX/TensorRT и поднятие model-server (ONNX Runtime / TensorRT / Triton).
**Использование:** отвечать на запросы фронтенда (FastAPI), масштабировать независимо от API.
**Реализация:**

* Docker-образ `tbank-inference:gpu` (ONNX Runtime / TensorRT engine, оптимизированный под T4).
* Интерфейс: REST/gRPC (один из стандартов) — простой контракт обмена: принять изображение → вернуть bboxes + confidence.
  **Особенности:** преднагрев (warm-up), batching strategy = 1 (latenсy-sensitive), мониторинг throughputs.

---

### 4. `env-service` — API фронтенд (FastAPI)

**Назначение:** публичный REST API сервис на порту `8000`, endpoint `/detect` для приёма изображений и возврата Pydantic-ответа. Отвечает за: загрузку / первичную проверку формата, pre-processing, агрегирование ответов от inference-сервиса, post-processing (NMS, фильтрация Tinkoff и т.д.), логирование.
**Реализация:**

* Docker-образ `tbank-api:latest` (uvicorn/gunicorn + FastAPI).
* В production: фронтенд может быть размещён за прокси (nginx) и балансировщиком.
  **Интеграция:** общается с `env-inference` по REST/gRPC; хранит логи/метрики в central logging/monitoring.

---

### 5. `env-dev` / `env-test` — разработка и CI тесты

**Назначение:** локальная разработка, unit/integration tests, быстрого отлова регрессий и smoke-tests.
**Реализация:** простые venv/conda среды или lightweight Docker образ `tbank-dev` (без GPU), с тестами, linters, pre-commit hooks.
**CI/CD:** пайплайны (GitHub Actions / GitLab CI) запускают тесты на PR, сборку докеров, basic integration tests (например, поднимают `tbank-inference` и `tbank-api` в docker-compose и выполняют запросы к `/detect`).

---

### 6. `env-monitoring` / observability

**Назначение:** сбор метрик, логов, алертинг, A/B тестирование моделей, отслеживание drift.
**Компоненты:** Prometheus / Grafana для метрик, ELK (или любой лог-агрегатор) для логов, W\&B / MLflow для трекинга экспериментов и артефактов.
**Реализация:** отдельный стек (можно в облаке) или интеграция с SaaS.

---

## Как окружения взаимодействуют (high-level flow)

1. `env-data-prep` генерирует COCO-датасет → сохраняет артефакты (аннотации, маски, кропы) в объектное хранилище / диск (например, S3 / NFS).
2. `env-training` берёт подготовленные данные → обучает модель → сохраняет веса и экспорт (ONNX/TensorRT) в артефакт-репозиторий.
3. `env-inference` разворачивает экспортированную модель → предоставляет endpoint для быстрого inference.
4. `env-service` (FastAPI) принимает пользовательские запросы → перенаправляет изображения к `env-inference`, выполняет post-processing → возвращает стандартизированный ответ.
5. `env-monitoring` собирает метрики и логи со всех окружений.

---

## Рекомендации по реализации (практические, но высокоуровневые)

* **Контейнеризация:** базовый принцип — всё, что нужно для воспроизводимости, упаковывается в Docker-образы (для training/inference/service/data-prep).
* **Версионирование артефактов:** веса моделей, COCO-аннотации и конфиги версионировать (Git LFS / S3 + метаданные).
* **Разделение ответственности:** фронт отвечает только за API и валидацию/агрегацию; модели и inference — в отдельном сервисе.
* **Security / secrets:** ключи OpenRouter, credentials хранятся в secrets manager (env vars / vault), не в git.
* **Reproducibility:** для training — фиксировать seed, версии библиотек, конфиги тренировки (yaml), логировать hyperparams в W\&B/MLflow.
* **Dev ergonomics:** docker-compose для локального поднятия `api` + `inference` (с CPU-режимом) для функционального теста. Для реального GPU inference — разворачивать `inference` на машине с GPU.

---

## Примеры имён образов / окружений (для стандартной организации)

* `tbank-data-prep:latest` — автоматизация аннотаций, пять batch-джобов.
* `tbank-train:gpu` — training image (PyTorch + CUDA).
* `tbank-inference:gpu` — optimized inference (ONNX/TensorRT).
* `tbank-api:latest` — FastAPI frontend.
* `tbank-dev:latest` — lightweight dev image (linters, тесты).
* `tbank-monitoring` — образ для метрик / логов или внешние SaaS.

---

## Краткая таблица соответствия окружений и целей

| Окружение        |                           Цель |     GPU нужен?    | Формат запуска |
| ---------------- | -----------------------------: | :---------------: | -------------- |
| `env-data-prep`  | Аннотация, подготовка датасета |    опционально    | venv / docker  |
| `env-training`   |             Тренировка моделей |      да (T4+)     | docker (GPU)   |
| `env-inference`  |              Быстрый inference | да (для TensorRT) | docker (GPU)   |
| `env-service`    |               FastAPI frontend |  нет (обычно CPU) | docker         |
| `env-dev/test`   |    Локальная разработка, тесты |        нет        | venv / docker  |
| `env-monitoring` |           Метрики, логирование |        нет        | сервисы/saas   |

---

## Заключение

Этот файл задаёт высокий уровень организации окружений: какие есть, зачем они нужны и как взаимодействуют. Следующие шаги — подготовить для каждого окружения отдельный документ с деталями зависимостей, примерами `Dockerfile`/`requirements`/`conda.yml`, скриптами запуска и инструкцией по деплою. Готов продолжить и сгенерировать `env`-шаблоны (Dockerfile + краткий `README`) для выбранных окружений — скажите, с какого окружения начать.

# Отборочный экзамен для трека Computer Vision

## Детекция логотипа Т-Банка

### Цель кейса

Создать REST API сервис, который сможет обнаруживать **логотип Т-Банка** (игнорируйте логотипы "Тинькофф" если они окажутся в выборке) на загружаемых изображениях и возвращать координаты найденных логотипов.

Вам предстоит разработать систему автоматического поиска и детекции логотипа Т-Банка на изображениях. **Логотип представляет собой стилизованную букву "Т" в щите** _(при этом **цвет может быть как желтый, так и произвольный**)_. Для этого потребуется некоторым образом разметить данные для того, чтобы собирать на их основе свое решение. Так же вам предстоит составить свой валидационный набор данных и реализовать подсчет качества своего решения на нем.

### Данные // пререквизиты

Мы предоставляем вам неразмеченный датасет для обучения и валидации, содержащий:

- Большое количество изображений различного содержания
- Изображения с логотипами Т-банка в различных условиях (разные размеры, углы поворота, освещение)
- Изображения без логотипов (для тестирования на ложные срабатывания)

Вы так же можете пополнять датасет для обучения любыми доступными вам способами. У организаторов остается размеченный приватный набор данных для проверки ваших решений.

### Ограничения

- Время обработки: не более `10` секунд на изображение
- Железо: Возможность запуска на видеокарте с 16GB видеопамяти (уровня google collab T4)
- Поддерживаемые форматы: `JPEG, PNG, BMP, WEBP`
- Порт сервиса: `8000`
- API: согласно описанному контракту

Контракт API:

```
from pydantic import BaseModel, Field
from typing import List, Optional
from fastapi import FastAPI, File, UploadFile

class BoundingBox(BaseModel):
    """Абсолютные координаты BoundingBox"""
    x_min: int = Field(..., description="Левая координата", ge=0)
    y_min: int = Field(..., description="Верхняя координата", ge=0)
    x_max: int = Field(..., description="Правая координата", ge=0)
    y_max: int = Field(..., description="Нижняя координата", ge=0)

class Detection(BaseModel):
    """Результат детекции одного логотипа"""
    bbox: BoundingBox = Field(..., description="Результат детекции")

class DetectionResponse(BaseModel):
    """Ответ API с результатами детекции"""
    detections: List[Detection] = Field(..., description="Список найденных логотипов")

class ErrorResponse(BaseModel):
    """Ответ при ошибке"""
    error: str = Field(..., description="Описание ошибки")
    detail: Optional[str] = Field(None, description="Дополнительная информация")

# Пример эндпоинта
@app.post("/detect", response_model=DetectionResponse)
async def detect_logo(file: UploadFile = File(...)):
    """
    Детекция логотипа Т-банка на изображении

    Args:
        file: Загружаемое изображение (JPEG, PNG, BMP, WEBP)

    Returns:
        DetectionResponse: Результаты детекции с координатами найденных логотипов
    """
    pass
```

### Ожидаемый формат решения

По результатам работы необходимо предоставить публичный GitHub репозиторий с полным исходным кодом решения. Решение должно быть упаковано в Docker контейнер, который запускается одной командой и поднимает REST API сервис на порту `8000`. API должен строго соответствовать предоставленной Pydantic спецификации с эндпоинтом `/detect` для загрузки изображений и получения координат найденных логотипов. В корне репозитория обязательно должен находиться файл `README.md` с подробными инструкциями по сборке и запуску Docker контейнера.

Дополнительно в `README.md` необходимо описать подход к решению задачи с достаточной степенью подробности. Веса обученной модели можете выложить на любой открытый файлообменник и приложить ссылку на их скачивание в `README.md`.

Так же вам необходимо реализовать скрипт валидации качества решения и подсчета метрик на отобранных и размеченных примерах. Для оценки воспроизводимости результата валидационную выборку необходимо по аналогии с моделью выложить в открытый доступ (github и/или открытый файлообменник).

### Критерии оценивания

1. **Точность детекции (25%)**

    - Precision и Recall на закрытом тестовом наборе, основной метрикой будет считать F1-score при IoU=0.5

2. **Техническое качество (25%)**
    
    - Качество кода и архитектуры
    - Обработка ошибок
    - Производительность (время обработки)
    - Использование best practices

3. **Документация (40%)**
    
    - Качество README.md
    - Подробное описание подхода к решению
    - Описание процесса работы с данными в процессе подготовки к решению.
    - Инструкции по запуску и использованию
    - Результаты работы модели на вашей валидационной выборке (с отрисоваными результатами детекции)
    
4. **Дополнительные (в свободном формате) (10%)**

    - Предложения альтернативных подходов к решению
    - Проведенный анализ проблем решения и рассуждения по возможности их решения
    - Проведенный анализ производительности решения и предложение вариантов по его ускорению

### Подсказки

- Используйте **zero-shot** подходы для подготовки разметки данных.
- Обратите внимание на предобработку изображений и обработку negative примеров.
- Тестируйте решение на различных типах изображений, уделите время проверке качества разметки вашей валидационной выборки.
- Документируйте свои эксперименты и выбор подхода в процессе работы.
- Обращайте внимание на качество оформления `README.md`, пишите свои шаги по решению максимально подробно, документация будет проверяться в первую очередь.
- Вы свободны обогощать обучающую выборку данными из любых источников.

Удачи!